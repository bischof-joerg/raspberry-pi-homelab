# docker-compose.yml
# Monitoring stack for Raspberry Pi (ARM64) with IaC + basic hardening
# - Exposes ONLY Grafana by default
# - Alertmanager/VictoriaMetrics UIs are kept localhost-bound (enable LAN only if you really need it)

name: ${COMPOSE_PROJECT_NAME:-homelab-home-prod-mon}

services:

  alertmanager:
    image: prom/alertmanager:v0.28.0
    restart: unless-stopped
    networks: [monitoring]
    ports:
      - "127.0.0.1:9093:9093"
    volumes:
      - /srv/data/stacks/monitoring/alertmanager:/alertmanager
      # Config + templates come from the single volume prepared by the renderer
      - /srv/data/stacks/monitoring/alertmanager-config:/etc/alertmanager:ro
    command:
      - --config.file=/etc/alertmanager/alertmanager.yml
      - --storage.path=/alertmanager
    depends_on:
      alertmanager-config-render:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "wget", "--tries=1", "--spider", "http://127.0.0.1:9093/-/healthy"]
    labels:
      - "homelab.config-hash=${MONITORING_CONFIG_HASH:-unset}"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: true
    tmpfs:
      - /tmp

  # One-shot renderer: renders alertmanager.yml from template using envsubst and
  # copies templates into the same volume.
  alertmanager-config-render:
    image: alpine:3.20
    restart: "no"
    networks: [monitoring]

    # Compose interpolation must not hard-fail if SMTP isn't configured yet.
    # Strict validation happens at runtime only when ALERT_EMAIL_ENABLED=1.
    environment:
      ALERT_EMAIL_ENABLED: ${ALERT_EMAIL_ENABLED:-0}

      ALERT_EMAIL_TO: ${ALERT_EMAIL_TO:-}
      ALERT_SMTP_SMARTHOST: ${ALERT_SMTP_SMARTHOST:-}
      ALERT_SMTP_FROM: ${ALERT_SMTP_FROM:-}
      ALERT_SMTP_AUTH_USERNAME: ${ALERT_SMTP_AUTH_USERNAME:-}
      ALERT_SMTP_AUTH_PASSWORD: ${ALERT_SMTP_AUTH_PASSWORD:-}
      ALERT_SMTP_REQUIRE_TLS: ${ALERT_SMTP_REQUIRE_TLS:-}

      # Prevent compose warnings if these appear anywhere as ${...} by accident.
      ALERT_EMAIL_CRITICAL_YAML: ${ALERT_EMAIL_CRITICAL_YAML:-}
      ALERT_EMAIL_WARNING_YAML: ${ALERT_EMAIL_WARNING_YAML:-}

    volumes:
      - /srv/data/stacks/monitoring/alertmanager-config:/out
      - ../alertmanager/alertmanager.yml.tmpl:/in/alertmanager.yml.tmpl:ro
      - ../alertmanager/templates:/in/templates:ro

    command:
      - /bin/sh
      - -lc
      - |
        set -euo pipefail
        apk add --no-cache gettext

        if [ "$${ALERT_EMAIL_ENABLED:-0}" = "1" ]; then
          : "$${ALERT_EMAIL_TO:?missing ALERT_EMAIL_TO}"
          : "$${ALERT_SMTP_SMARTHOST:?missing ALERT_SMTP_SMARTHOST}"
          : "$${ALERT_SMTP_FROM:?missing ALERT_SMTP_FROM}"
          : "$${ALERT_SMTP_AUTH_USERNAME:?missing ALERT_SMTP_AUTH_USERNAME}"
          : "$${ALERT_SMTP_AUTH_PASSWORD:?missing ALERT_SMTP_AUTH_PASSWORD}"
          : "$${ALERT_SMTP_REQUIRE_TLS:?missing ALERT_SMTP_REQUIRE_TLS}"

          case "$ALERT_SMTP_REQUIRE_TLS" in
            true|false) ;;
            *)
              echo "ERROR: ALERT_SMTP_REQUIRE_TLS must be 'true' or 'false'" >&2
              exit 2
              ;;
          esac

          # Generate ready-to-insert YAML blocks (with actual values).
          # Indentation: 4 spaces so it's valid under the receiver item.
          ALERT_EMAIL_CRITICAL_YAML="$$(
            printf '%s\n' "    email_configs:"
            printf '      - to: "%s"\n' "$${ALERT_EMAIL_TO}"
            printf '        from: "%s"\n' "$${ALERT_SMTP_FROM}"
            printf '        smarthost: "%s"\n' "$${ALERT_SMTP_SMARTHOST}"
            printf '        auth_username: "%s"\n' "$${ALERT_SMTP_AUTH_USERNAME}"
            printf '        auth_password: "%s"\n' "$${ALERT_SMTP_AUTH_PASSWORD}"
            printf '        require_tls: %s\n' "$${ALERT_SMTP_REQUIRE_TLS}"
            printf '%s\n' "        send_resolved: true"
          )"
          ALERT_EMAIL_WARNING_YAML="$$ALERT_EMAIL_CRITICAL_YAML"
        else
          ALERT_EMAIL_CRITICAL_YAML="    webhook_configs: [] # Disabled by IAC"
          ALERT_EMAIL_WARNING_YAML="    webhook_configs: [] # Disabled by IAC"
        fi

        export ALERT_EMAIL_CRITICAL_YAML ALERT_EMAIL_WARNING_YAML

        # Render config: only substitute the two injected YAML blocks.
        # envsubst muss die Shell-Variablen mit $ (nicht $$) ansprechen
        envsubst '$$ALERT_EMAIL_CRITICAL_YAML $$ALERT_EMAIL_WARNING_YAML' \
          < /in/alertmanager.yml.tmpl > /out/alertmanager.yml

        chmod 0644 /out/alertmanager.yml

        mkdir -p /out/templates
        if [ -d /in/templates ]; then
          cp -a /in/templates/. /out/templates/ 2>/dev/null || true
        fi
        chmod -R a+rX /out/templates || true

        echo "Rendered /out/alertmanager.yml and copied templates to /out/templates"
        test -s /out/alertmanager.yml

    labels:
      - "homelab.config-hash=${MONITORING_CONFIG_HASH:-unset}"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: false
    # no mpfs: - /tmp section as the alertmanager-config-render service is a one-shot initialization container (it runs once and exits).
    # it woult only add slight overhead and is not needed.

  # --- New: VictoriaMetrics single-node TSDB ---
  victoriametrics:
    image: victoriametrics/victoria-metrics:v1.135.0
    restart: unless-stopped
    networks: [monitoring]
    # Localhost-bound UI/API for debugging; remove or move behind Traefik later.
    ports:
      - "127.0.0.1:8428:8428"
    volumes:
      - /srv/data/stacks/monitoring/victoriametrics:/victoria-metrics-data
    command:
      - -storageDataPath=/victoria-metrics-data
      - -retentionPeriod=30d
      - -httpListenAddr=:8428
    # temporarily disable healthchecks as it seems that endpoints are not available
    # healthcheck:
    #   test: ["CMD", "wget", "--tries=1", "--spider", "http://127.0.0.1:8428/health"]
    #   interval: 30s
    #   timeout: 10s
    #   retries: 3
    deploy:
      resources:
        limits:
          memory: 4G
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: true
    tmpfs:
      - /tmp

  # --- New: scrape agent -> remote_write into VictoriaMetrics ---
  vmagent:
    image: victoriametrics/vmagent:v1.135.0
    restart: unless-stopped
    networks: [monitoring]
    ports:
      - "127.0.0.1:8429:8429"
    depends_on:
      victoriametrics:
        condition: service_started
    volumes:
      - ../vmagent/vmagent.yml:/etc/vmagent/vmagent.yml:ro
    command:
      - -promscrape.config=/etc/vmagent/vmagent.yml
      - -remoteWrite.url=http://victoriametrics:8428/api/v1/write
      - -httpListenAddr=:8429
      - -promscrape.suppressScrapeErrors
      - -remoteWrite.tmpDataPath=/tmp/vmagent-remotewrite-data
    healthcheck:
      test: ["CMD", "wget", "--tries=1", "--spider", "http://127.0.0.1:8429/ready"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    labels:
      - "homelab.config-hash=${MONITORING_CONFIG_HASH:-unset}"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: true
    tmpfs:
      - /tmp

  # --- New: alert rules evaluation -> Alertmanager ---
  vmalert:
    image: victoriametrics/vmalert:v1.135.0
    restart: unless-stopped
    networks: [monitoring]
    depends_on:
      victoriametrics:
        condition: service_started
      alertmanager:
        condition: service_started
    # Localhost-bound UI for debugging.
    ports:
      - "127.0.0.1:8880:8880"
    volumes:
      - ../vmalert/rules:/etc/vmalert/rules:ro
    command:
      - -rule=/etc/vmalert/rules/*.yml
      - -datasource.url=http://victoriametrics:8428
      - -notifier.url=http://alertmanager:9093
      - -remoteWrite.url=http://victoriametrics:8428
      - -remoteRead.url=http://victoriametrics:8428
      - -httpListenAddr=:8880
    healthcheck:
      test: ["CMD", "wget", "--tries=1", "--spider", "http://127.0.0.1:8880/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 20s
    labels:
      - "homelab.config-hash=${MONITORING_CONFIG_HASH:-unset}"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: true
    tmpfs:
      - /tmp

  grafana:
    image: grafana/grafana:11.4.2
    restart: unless-stopped
    networks: [monitoring]
    ports:
      - "3000:3000"
    environment:
      # secrets in env_file (and keep it out of git)
      GF_SECURITY_ADMIN_USER: ${GRAFANA_ADMIN_USER:-}
      GF_SECURITY_ADMIN_PASSWORD: ${GRAFANA_ADMIN_PASSWORD:-}
      GF_USERS_ALLOW_SIGN_UP: "false"
      GF_AUTH_ANONYMOUS_ENABLED: "false"
      # Optional: enable Grafana's VictoriaMetrics metrics endpoint
      GF_METRICS_ENABLED: "true"
      # Disabling sending usage statistics to Grafana Labs
      GF_ANALYTICS_REPORTING_ENABLED: "false"
      GF_SERVER_ENABLE_GZIP: "true" # Better performance on Pi
      # Grafana plugin preinstall (pinned)
      # Prefer the newer env var over GF_INSTALL_PLUGINS
      GF_PLUGINS_PREINSTALL: >
        victoriametrics-logs-datasource@0.24.0
    volumes:
      - /srv/data/stacks/monitoring/grafana:/var/lib/grafana
      - ../grafana/provisioning:/etc/grafana/provisioning:ro
      - ../grafana/dashboards:/var/lib/grafana/dashboards:ro
    healthcheck:
      test: ["CMD", "curl", "-f", "http://127.0.0.1:3000/api/health"]
      interval: 30s
      timeout: 10s
    labels:
      - "homelab.config-hash=${MONITORING_CONFIG_HASH:-unset}"
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    # Grafana needs write access to /var/lib/grafana (volume), so not fully read-only
    tmpfs:
      - /tmp

  node-exporter:
    image: quay.io/prometheus/node-exporter:v1.8.2
    restart: unless-stopped
    networks: [monitoring]
    # Do NOT expose to LAN; vmagent scrapes it via Docker network
    # ports:
    #   - "9100:9100"
    pid: host
    user: "65534:65534"
    command:
      - --path.rootfs=/host
      - --collector.filesystem.mount-points-exclude=^/(dev|proc|sys|run|var/lib/docker/.+)($|/)
      - --collector.filesystem.fs-types-exclude=^(autofs|binfmt_misc|bpf|cgroup2?|configfs|debugfs|devpts|devtmpfs|fusectl|hugetlbfs|mqueue|nsfs|overlay|proc|pstore|rpc_pipefs|securityfs|squashfs|sysfs|tracefs)$
    volumes:
      - /:/host:ro,rslave
    logging:
      driver: "json-file"
      options:
        max-size: "5m"
    security_opt:
      - no-new-privileges:true
    cap_drop: [ALL]
    read_only: true
    tmpfs:
      - /tmp

  cadvisor:
    image: ghcr.io/google/cadvisor:0.56.2
    restart: unless-stopped
    # Use root and privileged to ensure cgroup v2 visibility on Pi 5 kernel
    user: root
    # This is non-negotiable on the Pi 5. cAdvisor must be able to move across namespaces to inspect other containers' resource usage.
    privileged: true
    networks: [monitoring]
    # Do NOT expose to LAN; vmagent scrapes it via Docker network
    # ports:
    #   - "8080:8080"
    pid: host
    devices:
      - /dev/kmsg:/dev/kmsg
    volumes:
      - /etc/machine-id:/etc/machine-id:ro
      - /run/containerd/containerd.sock:/run/containerd/containerd.sock:ro
      - /sys/fs/cgroup:/sys/fs/cgroup:ro # Explicit cgroup v2 mount
      - /:/rootfs:ro
      - /var/run/docker.sock:/var/run/docker.sock:rw
      - /sys:/sys:ro
      - /var/lib/docker:/var/lib/docker:ro
    command: # recommended flags for VictoriaMetrics integration + performance on Pi
      # Reduce CPU usage by checking containers less frequently essential for Pi resource management
      - --housekeeping_interval=30s
      - --max_housekeeping_interval=60s
      - --event_storage_event_limit=default=0
      - --event_storage_age_limit=default=0
      # Prevents cAdvisor from trying to monitor the whole host, focusing only on containers
      - --docker_only=true
      # Enable filtering metrics in Grafana by the labels set in compose file
      - --store_container_labels=true
      # Added for Pi 5 / cgroup v2 handling:
      - --enable_load_reader=false
      - --allow_dynamic_housekeeping=true
      # Use this only if logs show "container not found in any cgroup"
      # - --cgroup_hierarchy_root=/sys/fs/cgroup # Forces cAdvisor to the correct Cgroup V2 root on Pi OS
    logging:
      driver: "json-file"
      options:
        max-size: "5m"

  victorialogs:
    image: victoriametrics/victoria-logs:v1.44.0
    command:
      - --storageDataPath=/vlogs
      - --httpListenAddr=:9428
      # Guardrail: cap disk usage for logs (bytes)
      - --retention.maxDiskSpaceUsageBytes=200000000000
    networks: [monitoring]
    ports:
      - "127.0.0.1:9428:9428"
    mem_limit: 2g
    read_only: true
    tmpfs:
      - /tmp
    cap_drop: [ALL]
    security_opt:
      - no-new-privileges:true
    volumes:
      - victorialogs-data:/vlogs

  vector:
    image: timberio/vector:0.51.1-distroless-libc
    command: ["--config", "/etc/vector/vector.yaml"]
    networks:
      - monitoring
      - apps
    environment:
      - HOST_NODE_NAME=${HOSTNAME:-rpi-hub}
      - VECTOR_CONFIG=/etc/vector/vector.yaml
    depends_on:
      victorialogs:
        condition: service_started
    # Needs journald access; see runbook notes below.
    user: "0:0"
    read_only: true
    tmpfs:
      - /tmp
      - /var/lib/vector
    cap_drop: [ALL]
    security_opt:
      - no-new-privileges:true
    volumes:
      - ../vector/vector.yaml:/etc/vector/vector.yaml:ro
      # journald access (runtime + persistent)
      - /run/log/journal:/run/log/journal:ro
      - /var/log/journal:/var/log/journal:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /etc/machine-id:/etc/machine-id:ro

networks:
  monitoring:
    external: true
    name: monitoring
  apps:
    external: true
    name: apps

volumes:
  victorialogs-data:
